{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T19:26:58.312085Z",
     "start_time": "2025-10-31T19:26:58.228305Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--limit LIMIT] [--samples SAMPLES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/vikkyfury/Library/Jupyter/runtime/kernel-e200e57c-425b-48e7-9264-d3c058f1953d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikkyfury/Desktop/call_center/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T19:22:03.699394Z",
     "start_time": "2025-10-31T19:22:03.692538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_json_safe(raw: bytes) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        return orjson.loads(raw)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return json.loads(raw.decode(\"utf-8\", errors=\"ignore\"))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def extract_plain_text(example: Dict[str, Any]) -> str:\n",
    "    # 1) common direct fields\n",
    "    for k in [\"transcript\", \"text\"]:\n",
    "        v = example.get(k)\n",
    "        if isinstance(v, str):\n",
    "            return v\n",
    "    # 2) list-like turns\n",
    "    for k in [\"dialog\", \"dialogue\", \"turns\", \"utterances\"]:\n",
    "        v = example.get(k)\n",
    "        if isinstance(v, list):\n",
    "            parts = []\n",
    "            for item in v:\n",
    "                if isinstance(item, dict):\n",
    "                    for tk in (\"text\", \"utterance\", \"content\"):\n",
    "                        tv = item.get(tk)\n",
    "                        if isinstance(tv, str):\n",
    "                            parts.append(tv)\n",
    "                elif isinstance(item, str):\n",
    "                    parts.append(item)\n",
    "            if parts:\n",
    "                return \"\\n\".join(parts)\n",
    "    # 3) fallback: join any reasonable strings\n",
    "    strings = []\n",
    "    for k, v in example.items():\n",
    "        if isinstance(v, str) and 5 <= len(v) <= 20000:\n",
    "            strings.append(v)\n",
    "    return \"\\n\".join(strings)\n",
    "\n",
    "def iter_zip_json_records_with_names(zip_path: Path):\n",
    "    \"\"\"Yield (member_name, json_obj) pairs for each JSON inside the zip.\"\"\"\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        for name in zf.namelist():\n",
    "            if not name.endswith(\".json\"):\n",
    "                continue\n",
    "            try:\n",
    "                with zf.open(name) as f:\n",
    "                    raw = f.read()\n",
    "                obj = read_json_safe(raw)\n",
    "                if not obj:\n",
    "                    logging.warning(f\"SKIP malformed JSON: {name}\")\n",
    "                    continue\n",
    "                yield name, obj\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"SKIP error reading {name}: {e}\")\n",
    "                continue\n",
    "\n",
    "def norm(s: Optional[str]) -> str:\n",
    "    return \" \".join(str(s or \"\").strip().split())\n",
    "\n",
    "def is_target(domain: Optional[str], topic: Optional[str], fname: str) -> bool:\n",
    "    \"\"\"True iff this record belongs to the exact Medicare_inbound (USA- USA) bucket.\"\"\"\n",
    "    d = norm(domain)\n",
    "    t = norm(topic)\n",
    "    if d == TARGET_LABEL or t == TARGET_LABEL:\n",
    "        return True\n",
    "    return TARGET_LABEL in fname\n"
   ],
   "id": "c6f3eae119348971",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T19:22:20.223136Z",
     "start_time": "2025-10-31T19:22:05.208561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LIMIT = 5000    # adjust as needed; set higher for more rows\n",
    "SAMPLES = 50    # how many raw .txt samples to dump for quick reading\n",
    "\n",
    "rows = []\n",
    "skipped = 0\n",
    "sample_dir = PROCESSED_DIR / \"medicare_inbound_samples\"\n",
    "sample_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for zname in ZIP_FILES:\n",
    "    print(f\"Downloading {zname} ...\")\n",
    "    local = hf_hub_download(REPO_ID, filename=zname, repo_type=\"dataset\")\n",
    "    zpath = Path(local)\n",
    "    print(f\"Scanning {zpath.name} ...\")\n",
    "\n",
    "    for fname, rec in tqdm(iter_zip_json_records_with_names(zpath), desc=f\"scan {zpath.name}\"):\n",
    "        domain = rec.get(\"domain\") or rec.get(\"industry\") or rec.get(\"category\")\n",
    "        topic  = rec.get(\"topic\")  or rec.get(\"subtopic\")\n",
    "\n",
    "        if not is_target(domain, topic, fname):\n",
    "            continue\n",
    "\n",
    "        text = extract_plain_text(rec)\n",
    "        if not text:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"source_zip\": zpath.name,\n",
    "            \"source_file\": fname,\n",
    "            \"domain\": domain,\n",
    "            \"topic\": topic,\n",
    "            \"text\": text[:50000]  # safety cap\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "        if len(rows) <= SAMPLES:\n",
    "            out_name = f\"sample_{len(rows):04d}__{Path(fname).stem[:60]}.txt\"\n",
    "            (sample_dir / out_name).write_text(text[:100000], encoding=\"utf-8\")\n",
    "\n",
    "        if len(rows) >= LIMIT:\n",
    "            break\n",
    "    if len(rows) >= LIMIT:\n",
    "        break\n",
    "\n",
    "if not rows:\n",
    "    print(\"No matches found for EXACT label 'Medicare_inbound (USA- USA)'. Confirm the label in metadata/file paths.\")\n",
    "else:\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_parquet = PROCESSED_DIR / \"medicare_inbound_usaUSA.parquet\"\n",
    "    out_csv = PROCESSED_DIR / \"medicare_inbound_usaUSA_preview.csv\"\n",
    "    df.to_parquet(out_parquet, index=False)\n",
    "    df.head(200).to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"Saved {len(rows)} rows -> {out_parquet}\")\n",
    "    print(f\"Preview (first 200) -> {out_csv}\")\n",
    "    print(f\"Raw text samples ({min(SAMPLES,len(rows))}) -> {sample_dir}\")\n",
    "    print(f\"Skipped empty-text records: {skipped}\")\n"
   ],
   "id": "318e89abc9a790e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading medicare_inbound.zip ...\n",
      "Scanning medicare_inbound.zip ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "scan medicare_inbound.zip: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37459cbf0706428aafb4b0939577b39f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches found for EXACT label 'Medicare_inbound (USA- USA)'. Confirm the label in metadata/file paths.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T19:22:27.787757Z",
     "start_time": "2025-10-31T19:22:27.784874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'df' in locals():\n",
    "    display(df.head(3))\n",
    "    print(\"\\nDomain values (top 5):\")\n",
    "    print(df['domain'].value_counts(dropna=False).head(5))\n",
    "    print(\"\\nTopic values (top 5):\")\n",
    "    print(df['topic'].value_counts(dropna=False).head(5))\n",
    "else:\n",
    "    print(\"Nothing collected yet. Re-run the extraction cell above.\")\n"
   ],
   "id": "123bc701d00e208f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing collected yet. Re-run the extraction cell above.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "69c3a84711a66bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
